{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis program is designed to take covid-19 data and a shapefile\\nfrom the internet and wrangle the data then produce webmaps in html\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This program is designed to take covid-19 data and a shapefile\n",
    "from the internet and wrangle the data then produce webmaps in html\n",
    "\"\"\"\n",
    "\n",
    "# resources\n",
    "# the covid-19 data provided by johns-hopkins-university \n",
    "# https://github.com/CSSEGISandData/COVID-19.git  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import wget\n",
    "import datetime\n",
    "import time\n",
    "import folium\n",
    "from folium import plugins\n",
    "import branca.colormap as cm\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# so that u don't have warnings\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello \n",
      "This program is designed to take covid-19 data and a shapefile \n",
      "from the internet and wrangle the data then produce webmaps in html. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "start_time = time.time()\n",
    "# an introduction\n",
    "print('Hello \\n'\n",
    "      'This program is designed to take covid-19 data and a shapefile \\n'\n",
    "      'from the internet and wrangle the data then produce webmaps in html. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path creation\n",
    "current_path = os.getcwd()\n",
    "data_path = current_path + '\\\\data_down'\n",
    "webmaps_path = current_path + '\\\\webmaps'\n",
    "shapefile_path = current_path + '\\\\shapefile'\n",
    "csv_path = current_path + '\\\\csv and shapefiles'\n",
    "\n",
    "# creating a folder to host the downloaded data\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "\n",
    "# creating a folder to host the webmaps\n",
    "if not os.path.exists(webmaps_path):\n",
    "    os.mkdir(webmaps_path)\n",
    "\n",
    "# creating a folder to host the csv files\n",
    "if not os.path.exists(csv_path):\n",
    "    os.mkdir(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting required files from the internet\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "    'time_series_covid19_confirmed_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "    'time_series_covid19_deaths_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "    'time_series_covid19_recovered_global.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting old csv files\n",
    "if os.path.isfile(data_path + '\\\\time_series_covid19_confirmed_global.csv'):\n",
    "    os.unlink(data_path + '\\\\time_series_covid19_confirmed_global.csv')\n",
    "if os.path.isfile(data_path + '\\\\time_series_covid19_deaths_global.csv'):\n",
    "    os.unlink(data_path + '\\\\time_series_covid19_deaths_global.csv')\n",
    "if os.path.isfile(data_path + '\\\\time_series_covid19_recovered_global.csv'):\n",
    "    os.unlink(data_path + '\\\\time_series_covid19_recovered_global.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The needed files was downloaded.\n",
      "The program read the needed files.\n"
     ]
    }
   ],
   "source": [
    "# downloading the required files\n",
    "for url in urls:\n",
    "    filename = wget.download(url, out=data_path)\n",
    "print('The needed files was downloaded.')\n",
    "# inserting the required files\n",
    "df_confirmed = pd.read_csv(data_path + '\\\\time_series_covid19_confirmed_global.csv')\n",
    "df_death = pd.read_csv(data_path + '\\\\time_series_covid19_deaths_global.csv')\n",
    "df_recovered = pd.read_csv(data_path + '\\\\time_series_covid19_recovered_global.csv')\n",
    "world = gpd.read_file(shapefile_path + '\\\\World_Map.shp')\n",
    "print('The program read the needed files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the dates\n",
    "dates = df_confirmed.columns[4:]\n",
    "\n",
    "# melt dataframes into pivot like dataframes\n",
    "df_confirmed_melt = df_confirmed.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "                                      value_vars=dates, var_name='Date', value_name='Confirmed')\n",
    "\n",
    "df_death_melt = df_death.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "                              value_vars=dates, var_name='Date', value_name='Deaths')\n",
    "\n",
    "df_recovered_melt = df_recovered.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "                                      value_vars=dates, var_name='Date', value_name='Recovered')\n",
    "\n",
    "# merging dataframes to get all values together\n",
    "df = pd.merge(left=df_confirmed_melt, right=df_death_melt, how='left',\n",
    "              on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long'])\n",
    "\n",
    "df = pd.merge(left=df, right=df_recovered_melt, how='left',\n",
    "              on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# fill null with 0\n",
    "df['Recovered'] = df['Recovered'].fillna(0)\n",
    "\n",
    "# converting the Recovered column into int datatype\n",
    "df['Recovered'] = df['Recovered'].astype('int')\n",
    "\n",
    "# removing extra recovered values from the merge\n",
    "df = df[df['Province/State'].str.contains('Recovered') != True]\n",
    "\n",
    "# removing county wise data to avoid double values\n",
    "df = df[df['Province/State'].str.contains(',') != True]\n",
    "\n",
    "# creating an Active column for analysis \n",
    "df['Active'] = df['Confirmed'] - df['Deaths'] - df['Recovered']\n",
    "\n",
    "cols = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n",
    "# giving all the null values (0)\n",
    "df[cols] = df[cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by day, country for improving the quality of the data\n",
    "full_grouped = df.groupby(['Date', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n",
    "\n",
    "# creating the new cases columns\n",
    "temp = full_grouped.groupby(['Country/Region', 'Date', ])['Confirmed', 'Deaths', 'Recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "\n",
    "temp.loc[mask, 'Confirmed'] = np.nan\n",
    "temp.loc[mask, 'Deaths'] = np.nan\n",
    "temp.loc[mask, 'Recovered'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns \n",
    "temp.columns = ['Country/Region', 'Date', 'New cases', 'New deaths', 'New recovered']\n",
    "\n",
    "# merging new values\n",
    "full_grouped = pd.merge(full_grouped, temp, on=['Country/Region', 'Date'])\n",
    "\n",
    "# filling na with 0\n",
    "full_grouped = full_grouped.fillna(0)\n",
    "\n",
    "# fixing data types\n",
    "cols = ['New cases', 'New deaths', 'New recovered']\n",
    "full_grouped[cols] = full_grouped[cols].astype('int')\n",
    "\n",
    "full_grouped['New cases'] = full_grouped['New cases'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "full_grouped = full_grouped.groupby(['Date', 'Country/Region'])[\n",
    "    'Confirmed', 'Deaths', 'Recovered', 'New cases', 'New deaths', 'New recovered'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "full_grouped.rename(columns={'Country/Region': 'Country'}, inplace=True)\n",
    "\n",
    "full_grouped = full_grouped[full_grouped.Country != 'Diamond Princess']\n",
    "full_grouped = full_grouped[full_grouped.Country != 'MS Zaandam']\n",
    "full_grouped = full_grouped[full_grouped.Country != 'Summer Olympics 2020']\n",
    "\n",
    "# dropping two null values in china and in canada and renaming DataFrame\n",
    "df = full_grouped.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping islands that can affect the data\n",
    "df = df[df.Country != 'Diamond Princess']\n",
    "df = df[df.Country != 'MS Zaandam']\n",
    "df = df[df.Country != 'Summer Olympics 2020']\n",
    "# this two are extra from another column but i left them just for remembering if i wanted to use them again\n",
    "# df = df[df.State!='Grand Princess'] \n",
    "# df = df[df.State!='Diamond Princess']\n",
    "\n",
    "# This places doesn't have population data \n",
    "# Åland Islands, Bouvet Island, British Indian Ocean Territory, Cocos (Keeling) Islands, French Southern and Antarctic Lands, \n",
    "# Guernsey, Heard Island and McDonald Islands, Jersey islands, Netherlands Antilles, Norfolk Island, Green land\n",
    "# Pitcairn Islands, Saint Helena, Svalbard, United States Minor Outlying Islands, Wallis and Futuna Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shapefile data didn't match the DataFrame\n",
    "# editing the Country names to match the DataFrame\n",
    "world.replace('Viet Nam', 'Vietnam', inplace=True)\n",
    "world.replace('Brunei Darussalam', 'Brunei', inplace=True)\n",
    "world.replace('Cape Verde', 'Cabo Verde', inplace=True)\n",
    "world.replace('Democratic Republic of the Congo', 'Congo (Kinshasa)', inplace=True)\n",
    "world.replace('Congo', 'Congo (Brazzaville)', inplace=True)\n",
    "world.replace('Czech Republic', 'Czechia', inplace=True)\n",
    "world.replace('Swaziland', 'Eswatini', inplace=True)\n",
    "world.replace('Iran (Islamic Republic of)', 'Iran', inplace=True)\n",
    "world.replace('Korea, Republic of', 'Korea, South', inplace=True)\n",
    "world.replace(\"Lao People's Democratic Republic\", 'Laos', inplace=True)\n",
    "world.replace('Libyan Arab Jamahiriya', 'Libya', inplace=True)\n",
    "world.replace('Republic of Moldova', 'Moldova', inplace=True)\n",
    "world.replace('The former Yugoslav Republic of Macedonia', 'North Macedonia', inplace=True)\n",
    "world.replace('Syrian Arab Republic', 'Syria', inplace=True)\n",
    "world.replace('Taiwan', 'Taiwan*', inplace=True)\n",
    "world.replace('United Republic of Tanzania', 'Tanzania', inplace=True)\n",
    "world.replace('United States', 'US', inplace=True)\n",
    "world.replace('Palestine', 'West Bank and Gaza', inplace=True)\n",
    "\n",
    "# editing the Dataframe names to match the open street map\n",
    "df.replace('South Sudan', 'Sudan', inplace=True)\n",
    "df.replace('Micronesia', 'Federated States of Micronesia', inplace=True)\n",
    "df.replace('Taiwan*', 'Taiwan', inplace=True)\n",
    "\n",
    "# matching the column's name for a better match\n",
    "world.rename(columns={'NAME': 'Country'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the 'data' with 'world' geopandas geodataframe\n",
    "# gdf = world.merge(df, on=['Country'])\n",
    "\n",
    "# grouping the places together because it was created based on regions\n",
    "df = full_grouped.groupby(['Date', 'Country'])['Confirmed', 'Deaths', 'Recovered', 'New cases',\n",
    "                                               'New deaths'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the latitude and longitude file is not in ur drive the program will create one using osm\n",
    "if not os.path.isfile(shapefile_path + r'\\\\countries.csv'):\n",
    "    map_time = time.time()\n",
    "    from geopy.geocoders import Nominatim\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"app\")\n",
    "    lat = []\n",
    "    lon = []\n",
    "    df_country = df[df['Date'] == str(df['Date'].tolist())[-22:-12]][['Country', 'Confirmed']]\n",
    "    co_lis = df_country.Country.unique()\n",
    "    for location in co_lis:\n",
    "        location = geolocator.geocode(location)\n",
    "        if location is None:\n",
    "            lat.append(np.nan)\n",
    "            lon.append(np.nan)\n",
    "        else:\n",
    "            lat.append(location.latitude)\n",
    "            lon.append(location.longitude)\n",
    "    df_country['Lat'] = lat\n",
    "    df_country['Long'] = lon\n",
    "    df_country = df_country[['Country', 'Lat', 'Long']]\n",
    "    df_country.to_csv(shapefile_path + r'\\\\countries.csv')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - map_time\n",
    "    total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "    print('The program created a file for latitude and longitude from OSM and '\n",
    "          'saved it as a csv file in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program read the latitude and longitude file.\n"
     ]
    }
   ],
   "source": [
    "# turing values to positive in the New cases and New deaths\n",
    "df['New deaths'] = abs(df['New deaths'])\n",
    "df['New cases'] = abs(df['New cases'])\n",
    "\n",
    "# opening the latitude and longitude file for merging it with the Dataframe\n",
    "df_country = pd.read_csv(shapefile_path + r'\\\\countries.csv')\n",
    "df_country = df_country[['Country', 'Lat', 'Long']]\n",
    "print('The program read the latitude and longitude file.')\n",
    "\n",
    "# removing non useful data\n",
    "df = df[df['Confirmed'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program saved the total cases and deaths as a csv file.\n",
      "The program saved the total cases and deaths as a shapefile.\n"
     ]
    }
   ],
   "source": [
    "# merging dataframes for adding latitude and longitude\n",
    "df = pd.merge(left=df, right=df_country, how='left', on=['Country'])\n",
    "df.to_csv(csv_path + r'\\\\df.csv')\n",
    "# creating a total dataframe for the analysis\n",
    "total = df[df['Date'] == str(df['Date'].tolist())[-22:-12]][\n",
    "    ['Country', 'Confirmed', 'Deaths', 'Lat', 'Long']]\n",
    "total = total[['Country', 'Confirmed', 'Deaths', 'Lat', 'Long']].reset_index()\n",
    "total = total[['Country', 'Confirmed', 'Deaths', 'Lat', 'Long']]\n",
    "# saving the total dataframe as a csv file\n",
    "total.to_csv(csv_path + r'\\\\total.csv')\n",
    "print('The program saved the total cases and deaths as a csv file.')\n",
    "# creating a shape file contains the total cases and deaths\n",
    "gdf = world.merge(total, on=['Country'])\n",
    "gdf.to_file(csv_path + r'\\\\total.shp')\n",
    "print('The program saved the total cases and deaths as a shapefile.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program saved the daily cases and deaths as a csv file.\n"
     ]
    }
   ],
   "source": [
    "# creating a total dataframe for the analysis\n",
    "daily = df[['Country', 'New cases', 'New deaths', 'Lat', 'Long']]\n",
    "print('The program saved the daily cases and deaths as a csv file.')\n",
    "\n",
    "# saving the daily dataframe as a csv file\n",
    "daily.to_csv(csv_path + r'\\\\daily.csv')\n",
    "\n",
    "# creating a temporary Dataframe that starts after 01-04-2020 for the line chart\n",
    "df_temp = df[df['Date'] >= '2020-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot basemaps\n",
    "World_Imagery_tile = folium.raster_layers.TileLayer(tiles='https://server.arcgisonline.com/ArcGIS/rest/services/'\n",
    "                                                          'World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "                                                    attr='Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community',\n",
    "                                                    name='ESRI World Imagery',\n",
    "                                                    show=False)\n",
    "\n",
    "ocean_tile = folium.raster_layers.TileLayer(tiles='https://server.arcgisonline.com/ArcGIS/rest/services/'\n",
    "                                                  'Ocean_Basemap/MapServer/tile/{z}/{y}/{x}',\n",
    "                                            attr='Tiles &copy; Esri &mdash; Sources: GEBCO, NOAA, CHS, OSU, UNH, CSUMB, National Geographic, DeLorme, NAVTEQ, and Esri',\n",
    "                                            name='ESRI ocean tile',\n",
    "                                            show=True)\n",
    "\n",
    "grey_canvas_tile = folium.raster_layers.TileLayer(tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/'\n",
    "                                                        'World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}',\n",
    "                                                  attr='Tiles &copy; Esri &mdash; Esri, DeLorme, NAVTEQ',\n",
    "                                                  name='ESRI grey canvas',\n",
    "                                                  show=False)\n",
    "\n",
    "Dark_bm = folium.raster_layers.TileLayer(tiles='CartoDB Dark_Matter',\n",
    "                                         name='Dark basemap',\n",
    "                                         show=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the TimeSlider New cases map was created in 00:38.\n"
     ]
    }
   ],
   "source": [
    "# creating maps with a time slider\n",
    "map_time = time.time()\n",
    "\n",
    "gdf = df.merge(world, on='Country')\n",
    "\n",
    "# creating a date column in epoch format and turning it to a string\n",
    "gdf['date'] = (gdf['Date'] - datetime.datetime(1970, 1, 1)).dt.total_seconds()\n",
    "gdf['date'] = gdf['date'].astype(int).astype(str)\n",
    "\n",
    "# removing extra columns\n",
    "gdf = gdf[['Country', 'date', 'New cases', 'New deaths', 'geometry']]\n",
    "\n",
    "# resting index\n",
    "gdf = gdf.sort_values(['Country', 'date']).reset_index(drop=True)\n",
    "\n",
    "# creating a color map for the New cases\n",
    "max_colour = gdf['New cases'].quantile(0.9)\n",
    "min_colour = 0\n",
    "cmap = cm.linear.YlGn_09.scale(min_colour, max_colour)\n",
    "gdf['colour'] = gdf['New cases'].map(cmap)\n",
    "\n",
    "# creating a style dictionary\n",
    "country_list = gdf['Country'].unique().tolist()\n",
    "country_idx = range(len(country_list))\n",
    "style_dict = {}\n",
    "for i in country_idx:\n",
    "    countries = country_list[i]\n",
    "    result = gdf[gdf['Country'] == countries]\n",
    "    inner_dict = {}\n",
    "    for _, r in result.iterrows():\n",
    "        inner_dict[r['date']] = {'color': r['colour'], 'opacity': 0.7}\n",
    "    style_dict[str(i)] = inner_dict\n",
    "\n",
    "# creating a Geopandas dataframe for plotting\n",
    "states_geom_df = gdf[['geometry']]\n",
    "states_geom_gdf = gpd.GeoDataFrame(states_geom_df)\n",
    "states_geom_gdf = states_geom_gdf.drop_duplicates().reset_index()\n",
    "\n",
    "# creating the time slider map\n",
    "\n",
    "m = folium.Map(location=[20, 0], tiles=\"\", min_zoom=2, zoom_start=2.5, max_zoom=8, max_bounds=True)\n",
    "tsm = folium.plugins.TimeSliderChoropleth(\n",
    "    data=states_geom_gdf.to_json(),\n",
    "    styledict=style_dict).add_to(m)\n",
    "\n",
    "tsm = cmap.add_to(m)\n",
    "cmap.caption = \"Number of New cases\"\n",
    "ocean_tile.add_to(m)\n",
    "\n",
    "m.save(r'webmaps/TimeSlider New cases.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('\\nthe TimeSlider New cases map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the TimeSlider New deaths map was created in 00:43.\n"
     ]
    }
   ],
   "source": [
    "# creating a color map for the New deaths\n",
    "map_time = time.time()\n",
    "\n",
    "max_colour = gdf['New deaths'].quantile(0.99)\n",
    "min_colour = 0\n",
    "cmap = cm.linear.OrRd_09.scale(min_colour, max_colour)\n",
    "gdf['colour'] = gdf['New deaths'].map(cmap)\n",
    "\n",
    "# creating a style dictionary\n",
    "country_list = gdf['Country'].unique().tolist()\n",
    "country_idx = range(len(country_list))\n",
    "style_dict = {}\n",
    "for i in country_idx:\n",
    "    countries = country_list[i]\n",
    "    result = gdf[gdf['Country'] == countries]\n",
    "    inner_dict = {}\n",
    "    for _, r in result.iterrows():\n",
    "        inner_dict[r['date']] = {'color': r['colour'], 'opacity': 0.7}\n",
    "    style_dict[str(i)] = inner_dict\n",
    "\n",
    "# creating a Geopandas dataframe for plotting\n",
    "states_geom_df = gdf[['geometry']]\n",
    "states_geom_gdf = gpd.GeoDataFrame(states_geom_df)\n",
    "states_geom_gdf = states_geom_gdf.drop_duplicates().reset_index()\n",
    "\n",
    "# creating the time slider map\n",
    "m = folium.Map(location=[20, 0], tiles=\"\", min_zoom=2, zoom_start=2.5, max_zoom=8, max_bounds=True)\n",
    "tsm = folium.plugins.TimeSliderChoropleth(\n",
    "    data=states_geom_gdf.to_json(),\n",
    "    styledict=style_dict).add_to(m)\n",
    "\n",
    "tsm = cmap.add_to(m)\n",
    "cmap.caption = \"Number of New deaths\"\n",
    "ocean_tile.add_to(m)\n",
    "\n",
    "m.save(r'webmaps/TimeSlider New deaths.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('the TimeSlider New deaths map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total covid-19 cases chart map was created in 01:33.\n"
     ]
    }
   ],
   "source": [
    "# creating an up to date choropleth map for the total covid-19 cases with a line chart\n",
    "map_time = time.time()\n",
    "\n",
    "m = folium.Map(location=[20, 0], tiles=\"\", min_zoom=2, zoom_start=2.5, max_zoom=8, max_bounds=True)\n",
    "total_cases = folium.Choropleth(geo_data=world, data=total,\n",
    "                                name='total cases',\n",
    "                                key_on='feature.properties.Country',\n",
    "                                columns=['Country', 'Confirmed'],\n",
    "                                nan_fill_color='black',\n",
    "                                nan_fill_opacity=0.6,\n",
    "                                fill_color='YlGn',\n",
    "                                bins=6,\n",
    "                                fill_opacity=1,\n",
    "                                highlight=True,\n",
    "                                legend_name='Number of total cases',\n",
    "                                control=True,\n",
    "                                )\n",
    "\n",
    "# circle maker in layer control\n",
    "fg = folium.FeatureGroup(name='Data')\n",
    "\n",
    "for lat, lon, value, value2, name in zip(total['Lat'], total['Long'], total['Confirmed'], total['Deaths'],\n",
    "                                         total['Country']):\n",
    "    chart = alt.Chart(df_temp[df_temp['Country'].str.contains(name)]).mark_area(\n",
    "        color=\"lightgreen\", interpolate='step-after', line=True).encode(x='Date:T', y='New cases')\n",
    "    vis1 = chart.to_json()\n",
    "    folium.CircleMarker((lat, lon),\n",
    "                        radius=10,\n",
    "                        tooltip=('<strong>Country</strong>: ' + str(name).capitalize() + '<br>'\n",
    "                                                                                         '<strong>Total Cases</strong>: ' + str(\n",
    "                            value) + '<br>'\n",
    "                                     '<strong>Deaths</strong>: ' + str(value2) + '<br>'),\n",
    "                        popup=folium.Popup().add_child(folium.VegaLite(vis1)),\n",
    "                        color='green',\n",
    "                        fill_color='red',\n",
    "                        fill_opacity=0.7,\n",
    "                        control=False,\n",
    "                        show=True).add_to(fg)\n",
    "\n",
    "total_cases.add_to(m)\n",
    "m.add_child(fg)\n",
    "\n",
    "total_cases.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "\n",
    "ocean_tile.add_to(m)\n",
    "Dark_bm.add_to(m)\n",
    "World_Imagery_tile.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "folium.plugins.Fullscreen().add_to(m)\n",
    "\n",
    "m.save(r'webmaps/total covid-19 cases chart.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('the total covid-19 cases chart map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total covid-19 deaths chart map was created in 01:29.\n"
     ]
    }
   ],
   "source": [
    "# creating an up to date choropleth map for the total covid-19 deaths with a line chart\n",
    "map_time = time.time()\n",
    "\n",
    "m = folium.Map(location=[20, 0], tiles=\"\", min_zoom=2, zoom_start=3, max_zoom=8, max_bounds=True)\n",
    "\n",
    "total_deaths = folium.Choropleth(geo_data=world, data=total,\n",
    "                                 name='total Deaths',\n",
    "                                 key_on='feature.properties.Country',\n",
    "                                 columns=['Country', 'Deaths'],\n",
    "                                 nan_fill_color='black',\n",
    "                                 nan_fill_opacity=0.6,\n",
    "                                 fill_color='OrRd',\n",
    "                                 bins=7,\n",
    "                                 fill_opacity=1,\n",
    "                                 highlight=True,\n",
    "                                 legend_name='Number of total Deaths',\n",
    "                                 control=True,\n",
    "                                 show=True)\n",
    "# circle maker in layer control\n",
    "fg = folium.FeatureGroup(name='Data')\n",
    "\n",
    "for lat, lon, value, value2, name in zip(total['Lat'], total['Long'], total['Confirmed'], total['Deaths'],\n",
    "                                         total['Country']):\n",
    "    chart = alt.Chart(df_temp[df_temp['Country'].str.contains(name)]).mark_area(\n",
    "        color=\"red\", interpolate='step-after', line=True).encode(x='Date:T', y='New deaths')\n",
    "    vis1 = chart.to_json()\n",
    "    folium.CircleMarker((lat, lon),\n",
    "                        radius=10,\n",
    "                        tooltip=('<strong>Country</strong>: ' + str(name).capitalize() + '<br>'\n",
    "                                                                                         '<strong>Total Cases</strong>: ' + str(\n",
    "                            value) + '<br>'\n",
    "                                     '<strong>Deaths</strong>: ' + str(value2) + '<br>'),\n",
    "                        popup=folium.Popup().add_child(folium.VegaLite(vis1)),\n",
    "                        color='green',\n",
    "                        fill_color='red',\n",
    "                        fill_opacity=0.7,\n",
    "                        control=False,\n",
    "                        show=True).add_to(fg)\n",
    "\n",
    "total_deaths.add_to(m)\n",
    "m.add_child(fg)\n",
    "\n",
    "total_deaths.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "\n",
    "ocean_tile.add_to(m)\n",
    "Dark_bm.add_to(m)\n",
    "World_Imagery_tile.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "folium.plugins.Fullscreen().add_to(m)\n",
    "\n",
    "m.save(r'webmaps/total covid-19 deaths chart.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('the total covid-19 deaths chart map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total covid-19 layers map was created in 00:08.\n"
     ]
    }
   ],
   "source": [
    "# creating an up to date choropleth map for the total covid-19 cases and deaths\n",
    "map_time = time.time()\n",
    "\n",
    "m = folium.Map(location=[20, 0], tiles=\"\", min_zoom=2, zoom_start=2.5, max_zoom=8, max_bounds=True)\n",
    "total_cases = folium.Choropleth(geo_data=world, data=total,\n",
    "                                name='total cases',\n",
    "                                key_on='feature.properties.Country',\n",
    "                                columns=['Country', 'Confirmed'],\n",
    "                                nan_fill_color='black',\n",
    "                                nan_fill_opacity=0.6,\n",
    "                                fill_color='YlGn',\n",
    "                                bins=6,\n",
    "                                fill_opacity=1,\n",
    "                                highlight=True,\n",
    "                                legend_name='Number of total cases',\n",
    "                                control=True)\n",
    "\n",
    "total_deaths = folium.Choropleth(geo_data=world, data=total,\n",
    "                                 name='total Deaths',\n",
    "                                 key_on='feature.properties.Country',\n",
    "                                 columns=['Country', 'Deaths'],\n",
    "                                 nan_fill_color='black',\n",
    "                                 nan_fill_opacity=0.6,\n",
    "                                 fill_color='OrRd',\n",
    "                                 bins=7,\n",
    "                                 fill_opacity=1,\n",
    "                                 highlight=True,\n",
    "                                 legend_name='Number of total Deaths',\n",
    "                                 control=True,\n",
    "                                 show=False)\n",
    "total_cases.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "total_deaths.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "\n",
    "total_cases.add_to(m)\n",
    "total_deaths.add_to(m)\n",
    "\n",
    "ocean_tile.add_to(m)\n",
    "Dark_bm.add_to(m)\n",
    "World_Imagery_tile.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "folium.plugins.Fullscreen().add_to(m)\n",
    "\n",
    "m.save(r'webmaps/total covid-19 layers.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('the total covid-19 layers map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total cases to death dual map was created in 00:09.\n"
     ]
    }
   ],
   "source": [
    "# creating an up to date dual choropleth map the total covid-19 cases and deaths\n",
    "map_time = time.time()\n",
    "\n",
    "m = plugins.DualMap(location=[20, 0], tiles='', layout='horizontal', zoom_start=2, max_bounds=True, syncCursor=True)\n",
    "\n",
    "# adding the total cases to the left side of the dual map\n",
    "total_cases = folium.Choropleth(geo_data=world, data=total,\n",
    "                                name='total cases',\n",
    "                                key_on='feature.properties.Country',\n",
    "                                columns=['Country', 'Confirmed'],\n",
    "                                nan_fill_color='black',\n",
    "                                nan_fill_opacity=0.6,\n",
    "                                fill_color='YlGn',\n",
    "                                bins=6,\n",
    "                                fill_opacity=1,\n",
    "                                highlight=True,\n",
    "                                legend_name='Number of total cases',\n",
    "                                control=True)\n",
    "total_cases.add_to(m.m1)\n",
    "\n",
    "## for deleting the legend of the total cases\n",
    "# for key in total_cases._children:\n",
    "#     if key.startswith('color_map'):\n",
    "#         del (total_cases._children[key])\n",
    "\n",
    "# adding the total deaths to the right side of the dual map\n",
    "total_deaths = folium.Choropleth(geo_data=world, data=total,\n",
    "                                 name='total Deaths',\n",
    "                                 key_on='feature.properties.Country',\n",
    "                                 columns=['Country', 'Deaths'],\n",
    "                                 nan_fill_color='black',\n",
    "                                 nan_fill_opacity=0.6,\n",
    "                                 fill_color='OrRd',\n",
    "                                 bins=7,\n",
    "                                 fill_opacity=1,\n",
    "                                 highlight=True,\n",
    "                                 legend_name='Number of total Deaths',\n",
    "                                 control=True)\n",
    "total_deaths.add_to(m.m2)\n",
    "## for deleting the legend of the total deaths\n",
    "# for key in total_deaths._children:\n",
    "#     if key.startswith('color_map'):\n",
    "#         del (total_deaths._children[key])\n",
    "\n",
    "# folium.GeoJsonTooltip(fields=['Country']).add_to(total_cases.geojson)\n",
    "total_cases.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "total_deaths.geojson.add_child(folium.features.GeoJsonTooltip(['Country']))\n",
    "\n",
    "ocean_tile.add_to(m)\n",
    "World_Imagery_tile.add_to(m)\n",
    "Dark_bm.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save(r'webmaps/total cases to death dual map.html')\n",
    "c+=1\n",
    "end_time = time.time()\n",
    "total_time = end_time - map_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('the total cases to death dual map was created in', total_time + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The program created 6 maps. \n",
      "Total Execution time is: 04:52.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(total_time))\n",
    "print('\\nThe program created', c, 'maps. \\n' + 'Total Execution time is:', total_time + '.')\n",
    "# exit()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f6cd8ece63a20abe54dfe611a6fa3a13994bdaa6a05cfcbdf26583cdcaae15"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('AAST_final': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
